<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Elastic web crawler known issues | Enterprise Search documentation [main] | Elastic</title>
<meta class="elastic" name="content" content="Elastic web crawler known issues | Enterprise Search documentation [main]">

<link rel="home" href="index.html" title="Enterprise Search documentation [main]"/>
<link rel="up" href="crawler.html" title="Elastic web crawler"/>
<link rel="prev" href="crawler-extraction-rules.html" title="Web crawler content extraction rules"/>
<link rel="next" href="crawler-troubleshooting.html" title="Troubleshooting crawls"/>
<meta class="elastic" name="product_version" content="main"/>
<meta class="elastic" name="product_name" content="Enterprise Search"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Enterprise Search/Guide/main"/>
<meta name="DC.subject" content="Enterprise Search"/>
<meta name="DC.identifier" content="main"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Enterprise Search documentation [main]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="crawler.html">Elastic web crawler</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="crawler-extraction-rules.html">« Web crawler content extraction rules</a>
</span>
<span class="next">
<a href="crawler-troubleshooting.html">Troubleshooting crawls »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="crawler-known-issues"></a>Elastic web crawler known issues<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler-known-issues.asciidoc">edit</a></h2>
</div></div></div>

<p>The Elastic web crawler has the following known issues:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><span class="strong strong"><strong>The crawler does not crawl pure JavaScript single-page applications (SPAs)</strong></span>.</p>
<p>We recommend looking at <a href="https://developers.google.com/search/docs/advanced/javascript/dynamic-rendering" class="ulink" target="_blank" rel="noopener">dynamic rendering</a> to help your crawler properly index your JavaScript websites.
Another option is to serve a static HTML version of your Javascript website, using a solution such as <a href="https://prerender.io/" class="ulink" target="_blank" rel="noopener">Prerender</a>.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>The crawler does not support dynamic content</strong></span>.</p>
<p>The crawler does not execute JavaScript, and it only pulls text from HTML elements.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>URLs being indexed despite having duplicate content and a canonical URL setting</strong></span>.</p>
<p><a class="xref" href="crawler-content.html#crawler-content-canonical-url-link-tag" title="Canonical URL link tags">Canonical URL link tags</a> are embedded within HTML source for pages that duplicate the content of other pages.
Refer to <a class="xref" href="crawler-managing.html#crawler-managing-duplicate-documents" title="Duplicate document handling">Duplicate document handling</a> for details.
The crawler identifies duplicate content by hashing the content of default deduplication fields derived from the page.
These fields are defined by the configuration setting <code class="literal">connector.crawler.extraction.default_deduplication_fields</code>.</p>
<p>The web crawler checks your index for an existing document with the same content hash.
Users have faced issues where they set canonical link tags for a page that does not have <span class="strong strong"><strong><em>identical</em></strong></span> content, because the hashes are different.
However, upon inspection, the content is the same.</p>
<p>Use the following <span class="strong strong"><strong>workaround</strong></span>:</p>
<p>You can manage which <span class="strong strong"><strong>fields</strong></span> the web crawler uses to create the content hash.
If your pages all define canonical URLs, you could safely change your deduplication fields settings to include only the <code class="literal">url</code> field.
Otherwise, you may need more fields to help check for duplicates.
By default, the web crawler checks <code class="literal">body_content</code>, <code class="literal">headings</code>, <code class="literal">links</code>, <code class="literal">meta_description</code>, <code class="literal">meta_keywords</code>, and <code class="literal">title</code> fields.</p>
</li>
</ul>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="crawler-extraction-rules.html">« Web crawler content extraction rules</a>
</span>
<span class="next">
<a href="crawler-troubleshooting.html">Troubleshooting crawls »</a>
</span>
</div>
</div>
</body>
</html>
